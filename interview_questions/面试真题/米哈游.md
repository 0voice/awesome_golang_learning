## 米哈游
### 1. Goroutine 阻塞的话，是不是对应的M也会阻塞  
Goroutine（G）阻塞时，对应的 Machine（M，操作系统线程）是否阻塞，取决于**阻塞的类型**：  

- **会导致 M 阻塞的情况**：  
  当 G 因**系统调用（如文件 IO、网络 IO 的阻塞操作）、睡眠（`time.Sleep`）、等待锁（如 `sync.Mutex` 未释放时的 `Lock` 调用）** 等操作阻塞时，执行该 G 的 M 会被阻塞，无法执行其他 G。  
  - 例如：G 执行 `file.Read()` 进行磁盘 IO 时，M 会陷入内核态等待 IO 完成，期间无法调度其他 G。  

- **不会导致 M 阻塞的情况**：  
  当 G 因**等待 Channel 操作（如从空 Channel 读取、向满 Channel 写入）、`select` 等待、`runtime.Gosched()` 主动让出 CPU** 等用户态操作阻塞时，Gin 调度器会将该 G 从 M 上剥离，让 M 去执行其他就绪的 G（来自 P 的本地队列或全局队列），此时 M 不会阻塞。  
  - 例如：G 执行 `<-ch` 从空 Channel 读取时，调度器会将 G 标记为阻塞状态并放入等待队列，M 则继续执行其他 G。  

**总结**：G 阻塞时，M 是否阻塞取决于阻塞操作是否陷入内核态——内核态阻塞（如 IO）会导致 M 阻塞，用户态阻塞（如 Channel 等待）不会阻塞 M，M 会切换执行其他 G。  


### 2. 如何并发100个任务，但是同一时间最多运行的10个任务  
可以使用**带缓冲的 Channel 作为信号量**控制并发数量，核心思路是：用容量为 10 的 Channel 限制同时运行的任务数（获取信号量才能执行，完成后释放信号量）。  

示例代码如下：  
```go
package main

import (
	"fmt"
	"time"
)

// 任务函数：模拟耗时操作
func task(id int, sem chan struct{}) {
	defer func() {
		<-sem // 任务完成，释放信号量（从Channel取出一个元素）
	}()

	// 模拟任务执行（如网络请求、数据处理等）
	fmt.Printf("任务 %d 开始执行\n", id)
	time.Sleep(1 * time.Second) // 模拟耗时1秒
	fmt.Printf("任务 %d 执行完成\n", id)
}

func main() {
	const totalTasks = 100   // 总任务数
	const maxConcurrency = 10 // 最大并发数

	// 创建容量为10的信号量Channel
	sem := make(chan struct{}, maxConcurrency)

	// 启动100个任务
	for i := 0; i < totalTasks; i++ {
		sem <- struct{}{} // 获取信号量（向Channel放入一个元素），满则阻塞
		go task(i, sem)   // 启动goroutine执行任务
	}

	// 等待所有任务完成（需确保主goroutine不退出）
	// 这里简单等待足够长的时间，实际场景可用sync.WaitGroup
	time.Sleep(12 * time.Second)
	fmt.Println("所有任务执行完毕")
}
```



**代码说明**：  
1. **信号量控制**：  
   - 创建容量为 10 的 `sem` Channel，作为并发控制的“令牌桶”。  
   - 每个任务启动前，先向 `sem` 写入元素（`sem <- struct{}{}`）：若 Channel 已满（已有 10 个任务在运行），则阻塞等待，直到有任务释放信号量。  
   - 任务完成后，通过 `defer <-sem` 释放信号量，允许新任务获取令牌并执行。  

2. **改进方案（使用 `sync.WaitGroup`）**：  
   上述代码用 `time.Sleep` 等待任务完成不够优雅，实际开发中可结合 `sync.WaitGroup` 精确等待所有任务结束：  
   ```go
   func main() {
       const totalTasks = 100
       const maxConcurrency = 10
       
       sem := make(chan struct{}, maxConcurrency)
       var wg sync.WaitGroup
       wg.Add(totalTasks) // 注册总任务数
       
       for i := 0; i < totalTasks; i++ {
           sem <- struct{}{}
           go func(id int) {
               defer func() {
                   <-sem
                   wg.Done() // 任务完成，计数器减1
               }()
               // 任务逻辑...
               fmt.Printf("任务 %d 执行\n", id)
               time.Sleep(1 * time.Second)
           }(i)
       }
       
       wg.Wait() // 等待所有任务完成
       fmt.Println("所有任务执行完毕")
   }
   ```  

**核心原理**：通过带缓冲 Channel 的“容量限制”特性，实现并发数的精确控制，适用于需要限制资源占用（如数据库连接、网络请求）的场景。

### 3. golang 内存模型  
Go 内存模型定义了多 goroutine 之间共享内存的**可见性规则**，核心是规范“何时一个 goroutine 对变量的写入，能被另一个 goroutine 看到”。  

- **核心原则**：  
  1. **顺序一致性**：单个 goroutine 内的操作按代码顺序执行（编译器和 CPU 不会重排单 goroutine 内有依赖的操作）。  
  2. **同步原语保证可见性**：不同 goroutine 间的操作可见性需通过**同步事件**建立“ happens-before ”关系：  
     - 通道通信：向通道发送数据的操作 happens-before 从该通道接收数据的操作。  
     - 锁机制：`sync.Mutex` 或 `sync.RWMutex` 的解锁操作 happens-before 后续的加锁操作。  
     - `sync.WaitGroup`：`Add` 调用 happens-before `Wait` 返回；`Done` 调用 happens-before `Wait` 返回。  
     - `sync.Once`：`Do` 函数内的操作 happens-before 任何 `Do` 调用返回。  

- **示例**：若 goroutine A 执行 `x = 1`，goroutine B 读取 `x`，仅当 A 和 B 之间通过上述同步原语建立关系时，B 才能保证读到 `x=1`，否则可能读到旧值（因 CPU 缓存、指令重排等）。  


### 4. golang 并发模型  
go 采用**基于 CSP（Communicating Sequential Processes）的并发模型**，核心是“通过通信共享内存，而非通过共享内存通信”，具体表现为：  

- **goroutine**：轻量级用户态线程（由 go  runtime 调度），启动成本低（KB 级栈空间），支持百万级并发。  
- **channel**：goroutine 间通信的核心机制，通过传递数据实现同步与协作，避免共享内存带来的锁竞争。  
- **GMP 调度模型**：go  runtime 采用 G（goroutine）、M（操作系统线程）、P（逻辑处理器）三级结构调度 goroutine，结合工作窃取（work stealing）机制平衡负载，充分利用多核 CPU。  

- **与其他模型对比**：  
  - 不同于 Java 等语言的“共享内存 + 锁”模型，go 优先通过 channel 传递数据，减少锁的使用；  
  - 支持传统的同步原语（如 `sync.Mutex`、`sync.WaitGroup`），兼容共享内存模式。  


### 5. golang gc 原理 过程  
go 的垃圾回收（GC）是**并发标记-清除（Concurrent Mark and Sweep）** 算法，目标是在不停止业务（或仅短暂停止）的情况下回收未使用的内存，核心过程如下：  

1. **标记阶段（Mark）**：  
   - **初始标记（Stop The World，STW）**：暂停所有 goroutine（约 10-100 微秒），标记根对象（如全局变量、栈上变量）。  
   - **并发标记**：恢复 goroutine 运行，后台线程并发遍历对象引用关系，标记所有可达对象（被根对象或其他可达对象引用的对象）。  
   - **重新标记（STW）**：再次短暂暂停 goroutine，处理并发标记期间因 goroutine 运行导致的引用变化（如新增或删除的引用）。  

2. **清除阶段（Sweep）**：  
   - 并发清除未被标记的对象（不可达对象），回收其占用的内存，无需暂停 goroutine。  

3. **辅助 GC（Mutator Assist）**：  
   - 在 GC 过程中，goroutine 分配内存时会协助执行部分标记/清除工作，避免后台线程负载过高。  

- **优化点**：  
  - 采用**三色标记法**（白色：未标记；灰色：待处理；黑色：已标记）跟踪对象状态；  
  - 引入**写屏障（Write Barrier）** 记录并发标记期间的引用变化，减少重新标记的 STW 时间；  
  - go 1.19 后默认启用 **non-generational concurrent GC**，进一步降低延迟。  


### 6. channel 用途，原理  
#### 用途  
channel 是 goroutine 间通信的核心机制，主要用途包括：  
1. **传递数据**：在 goroutine 间安全传递数据，避免共享内存竞争。  
2. **同步控制**：通过无缓冲 channel 实现 goroutine 间的等待（如“生产者-消费者”模型）。  
3. **限制并发**：用带缓冲 channel 作为信号量，控制同时运行的 goroutine 数量。  
4. **通知退出**：通过关闭 channel 向多个 goroutine 发送退出信号。  

#### 原理  
channel 在底层是一个**带锁的循环队列**（或链表），由 `hchan` 结构体实现，核心字段包括：  
- `buf`：缓冲数组（仅带缓冲 channel 有），存储待发送的数据。  
- `sendq`：发送者等待队列，当 channel 满时，发送 goroutine 会阻塞并加入此队列。  
- `recvq`：接收者等待队列，当 channel 空时，接收 goroutine 会阻塞并加入此队列。  
- `lock`：互斥锁，保证 channel 操作的线程安全。  

- **操作逻辑**：  
  - 发送（`ch <- x`）：若有等待的接收者，直接将数据传递给接收者；否则若缓冲区未满，存入缓冲区；否则阻塞并加入 `sendq`。  
  - 接收（`x <- ch`）：若有等待的发送者，直接从发送者获取数据；否则若缓冲区非空，从缓冲区取数据；否则阻塞并加入 `recvq`。  
  - 关闭（`close(ch)`）：唤醒所有等待的发送者/接收者，发送者会 panic，接收者会收到零值和 `ok=false`。  


### 7. redis 数据结构，底层实现  
redis 支持多种数据结构，每种结构有特定的底层实现以优化性能：  

1. **字符串（String）**：  
   - 底层：简单动态字符串（SDS），是对 C 字符串的改进，记录长度避免遍历，支持预分配空间减少内存碎片。  
   - 用途：缓存、计数器（`INCR`）、分布式锁等。  

2. **哈希（Hash）**：  
   - 底层：  
     - 小数据量：压缩列表（ziplist），将键值对紧凑存储在连续内存，节省空间。  
     - 大数据量：哈希表（hashtable），通过链地址法解决哈希冲突。  
   - 用途：存储对象（如用户信息）。  

3. **列表（List）**：  
   - 底层：  
     - 小数据量：压缩列表（ziplist）。  
     - 大数据量：双向链表（linkedlist），支持高效的首尾操作。  
   - 用途：消息队列、最新列表（`LPUSH + LRANGE`）。  

4. **集合（Set）**：  
   - 底层：  
     - 整数集合（intset）：当元素为整数且数量少时，用连续内存存储。  
     - 哈希表（hashtable）：元素为字符串或数量大时，用哈希表存储（值为 `null`）。  
   - 用途：去重、交集/并集计算（`SINTER`、`SUNION`）。  

5. **有序集合（Sorted Set）**：  
   - 底层：  
     - 小数据量：压缩列表（ziplist），按分值排序存储。  
     - 大数据量：跳跃表（skiplist）+ 哈希表，跳跃表按分值排序，哈希表映射成员到分值，支持 O(logN) 级查询。  
   - 用途：排行榜、范围查询（`ZRANGEBYSCORE`）。  


### 8. 跳跃表查询插入复杂度  
跳跃表（Skiplist）是有序集合（Sorted Set）的核心底层结构，查询和插入的**平均时间复杂度为 O(logN)**，最坏情况为 O(N)（概率极低）。  

- **查询过程**：  
  从最高层索引开始，沿水平指针向右查找，若下一个节点的分值大于目标值，则下降一层继续查找，直到找到目标节点或到达底层。  
  - 因每层索引跳过部分节点（类似“二分查找”的分层优化），平均只需遍历 logN 个节点。  

- **插入过程**：  
  1. 先查找插入位置（同查询过程），记录各层的前驱节点。  
  2. 随机生成新节点的层数（概率上，越高层概率越低，通常不超过 logN）。  
  3. 在各层插入新节点，更新前驱节点的指针。  
  - 因层数随机且平均为 logN，插入操作的平均复杂度为 O(logN)。  

- **优势**：相比平衡树（如红黑树），跳跃表实现简单，插入无需旋转操作，适合高并发场景（redis 中广泛使用）。  


### 9. 进程，线程，协程  
进程、线程、协程是不同层级的执行单元，核心区别在于资源占用和调度方式：  

| 类型   | 定义                                                                 | 资源占用                 | 调度方式                     | 并发能力                     |  
|--------|----------------------------------------------------------------------|--------------------------|------------------------------|------------------------------|  
| 进程   | 操作系统资源分配的基本单位（独立内存、文件描述符等）                   | 大（MB级，创建销毁开销高） | 操作系统内核调度（抢占式）   | 低（切换需切换内存空间）     |  
| 线程   | 进程内的执行单元，共享进程资源                                       | 中（KB级栈内存）         | 操作系统内核调度（抢占式）   | 中（切换需保存寄存器）       |  
| 协程   | 用户态轻量级线程，由程序/runtime 调度，共享线程资源                   | 极小（KB级或更低）       | 用户态调度（非抢占式，协作式） | 极高（单线程可运行数万协程） |  

- **关系**：一个进程包含多个线程，一个线程可包含多个协程；协程依赖线程运行，但调度由用户态控制，效率远高于线程。  


### 10. kill 原理  
`kill` 命令的作用是**向进程发送信号（signal）**，进程根据信号类型执行相应操作（如终止、暂停等），而非直接“杀死”进程。  

- **原理**：  
  1. 用户执行 `kill [信号] 进程ID` 时，内核会查找目标进程，将信号加入其信号队列。  
  2. 进程从内核态返回用户态时，会检查信号队列，若有未处理的信号，执行预设的信号处理函数（如默认动作或自定义函数）。  

- **默认动作**：多数信号的默认动作是终止进程（如 `SIGTERM`、`SIGKILL`），部分信号会导致进程暂停（`SIGSTOP`）或忽略（`SIGCHLD`）。  


### 11. 除了 kill -9 还知道什么信号  
`kill` 命令可发送多种信号，常见信号及用途：  

| 信号编号 | 信号名   | 含义与用途                                                                 |  
|----------|----------|----------------------------------------------------------------------------|  
| 1        | `SIGHUP` | 终端挂断，常用于让进程重读配置文件（如 Nginx 用 `kill -1 PID` 重载配置）。   |  
| 2        | `SIGINT` | 中断信号，等同于 Ctrl+C，让进程优雅退出（可捕获并执行清理逻辑）。            |  
| 3        | `SIGQUIT`| 退出信号，等同于 Ctrl+\，进程退出并生成核心转储文件（用于调试）。            |  
| 9        | `SIGKILL`| 强制终止信号，进程无法捕获或忽略，立即终止（用于杀死无响应的进程）。        |  
| 15       | `SIGTERM`| 终止信号（默认），进程可捕获并执行清理操作（如释放资源），推荐优先使用。     |  
| 18       | `SIGCONT`| 继续信号，用于恢复被 `SIGSTOP` 暂停的进程。                                |  
| 19       | `SIGSTOP`| 暂停信号，进程无法捕获或忽略，强制暂停（需用 `SIGCONT` 恢复）。             |  

- 查看所有信号：`kill -l`；发送信号的两种方式：`kill -信号编号 PID` 或 `kill -信号名 PID`（如 `kill -SIGTERM 1234`）。  


### 12. 父进程调用 fork 后，不调用 waitpid 会怎样  
父进程调用 `fork()` 创建子进程后，若未调用 `wait()` 或 `waitpid()` 等待子进程结束，会导致**子进程成为僵尸进程（Zombie Process）**。  

- **原因**：  
  子进程终止后，内核会保留其进程控制块（PCB），存储退出状态等信息，等待父进程通过 `waitpid()` 获取。若父进程未调用 `waitpid()`，内核无法释放子进程的 PCB，子进程始终处于“僵尸态”。  

- **影响**：  
  僵尸进程不占用 CPU 和内存，但会消耗系统进程表项（有限资源），若大量积累会导致无法创建新进程。  

- **解决**：  
  1. 父进程主动调用 `waitpid()` 回收子进程；  
  2. 父进程退出，子进程由 init 进程（或 systemd）接管并回收；  
  3. 通过信号机制：父进程注册 `SIGCHLD` 信号处理函数，在子进程终止时自动调用 `waitpid()`。  


### 13. 僵尸进程  
僵尸进程（Zombie Process）是**已终止但未被父进程回收的进程**，处于 `Z` 状态（通过 `ps` 命令查看）。  

- **特点**：  
  - 已停止运行，不占用 CPU 和内存，但保留进程 ID（PID）和退出状态等信息（存储在 PCB 中）。  
  - 无法被 `kill` 命令杀死（包括 `kill -9`），因进程已终止，仅需父进程回收。  

- **产生原因**：  
  子进程终止后，父进程未调用 `wait()` 或 `waitpid()` 读取其退出状态，导致内核无法释放 PCB。  

- **危害**：  
  系统 PID 数量有限（如 Linux 默认为 32768），大量僵尸进程会耗尽 PID 资源，导致新进程无法创建。  

- **处理方式**：  
  - 父进程调用 `waitpid()` 回收子进程；  
  - 终止父进程，让 init 进程（PID=1）接管并回收僵尸进程。  


### 14. 线程间同步方式  
线程间同步用于协调多个线程对共享资源的访问，避免数据竞争，常见方式：  

1. **互斥锁（Mutex）**：  
   - 确保同一时间只有一个线程访问共享资源，其他线程需等待锁释放（如 C++ 的 `std::mutex`，Java 的 `ReentrantLock`）。  

2. **读写锁（RWMutex）**：  
   - 区分读操作和写操作，允许多个线程同时读，但写操作需独占锁（适合读多写少场景，如缓存）。  

3. **信号量（Semaphore）**：  
   - 通过计数器控制并发线程数，计数器>0时允许线程访问，减1；=0时阻塞（如限制同时访问数据库的线程数）。  

4. **条件变量（Condition Variable）**：  
   - 让线程等待某个条件成立，当条件满足时由其他线程唤醒（如“生产者-消费者”模型中，队列空时消费者等待，生产者添加数据后唤醒）。  

5. **屏障（Barrier）**：  
   - 等待所有线程到达某一点后再继续执行（如多线程分阶段任务，需等所有线程完成第一阶段才能进入第二阶段）。  

6. **原子操作（Atomic Operation）**：  
   - 通过 CPU 指令直接操作内存，无需锁（如 `std::atomic`），适用于简单计数器等场景，效率高于锁。  


### 15. 锁有哪些类型  
锁按功能和特性可分为多种类型：  

1. **互斥锁（Mutex）**：  
   - 最基础的锁，同一时间仅允许一个线程持有，用于保护临界区（如 `sync.Mutex` in Go）。  

2. **读写锁（RWMutex）**：  
   - 分读锁（共享锁）和写锁（排他锁），读锁可被多个线程同时持有，写锁独占（如 `sync.RWMutex` in Go）。  

3. **递归锁（Recursive Mutex）**：  
   - 允许同一线程多次获取锁（自动计数），避免死锁（如 Java 的 `ReentrantLock`）。  

4. **自旋锁（Spin Lock）**：  
   - 线程获取锁失败时不会阻塞，而是循环重试（自旋），适合锁持有时间短的场景（减少线程切换开销）。  

5. **乐观锁**：  
   - 不主动加锁，而是通过版本号或 CAS（Compare And Swap）机制检测冲突，冲突时重试（如数据库的乐观锁）。  

6. **悲观锁**：  
   - 假设冲突必然发生，访问资源前先加锁（如数据库的 `SELECT ... FOR UPDATE`）。  

7. **分布式锁**：  
   - 跨进程/机器的锁，通过中间件（如 Redis、ZooKeeper）实现，用于分布式系统（如防止重复任务执行）。  


### 16. 口述 topk  
TopK 问题指从海量数据中找出前 K 个最大（或最小）的元素，常见解决思路：  

1. **小根堆法（适合大数据量）**：  
   - 维护一个容量为 K 的小根堆，堆顶为当前第 K 大元素。  
   - 遍历所有数据，若元素大于堆顶，则替换堆顶并调整堆（下沉操作）；否则跳过。  
   - 遍历结束后，堆中元素即为前 K 大元素，时间复杂度 O(N logK)（N 为数据总量）。  
   - 优势：内存占用小（仅需存储 K 个元素），适合数据无法全部加载到内存的场景。  

2. **快排分区法（适合数据可全部加载到内存）**：  
   - 基于快速排序的分区思想，随机选择一个基准值，将数据分为“大于基准”和“小于基准”两部分。  
   - 若“大于基准”的元素数量 > K，则在该部分继续查找；若 < K，则在“小于基准”的部分查找剩余元素。  
   - 平均时间复杂度 O(N)，最坏 O(N²)（可通过随机基准优化）。  

3. **计数排序/桶排序（适合数据范围已知）**：  
   - 若数据是整数且范围不大（如 0-1000），可通过计数数组统计每个值的出现次数，再从大到小取前 K 个。  


### 17. 建堆过程  
建堆（以大根堆为例）是将无序数组转换为堆结构的过程，核心是“下沉”操作，步骤如下：  

1. **初始状态**：将数组视为完全二叉树（下标 i 的左孩子为 2i+1，右孩子为 2i+2，父节点为 (i-1)/2）。  

2. **从最后一个非叶子节点开始下沉**：  
   - 最后一个非叶子节点的下标为 `n/2 - 1`（n 为数组长度），从该节点向前遍历至根节点（下标 0）。  
   - 对每个节点执行“下沉”：比较节点与左右孩子的大小，若孩子更大则交换，交换后继续对新位置的节点下沉，直到满足堆性质（父节点 >= 子节点）。  

3. **完成建堆**：  
   - 所有节点处理完毕后，数组满足大根堆性质（根节点为最大值，每个父节点 >= 子节点）。  

- **示例**：对数组 `[3, 9, 2, 1, 4, 5]` 建大根堆：  
  - 最后一个非叶子节点是下标 2（值为 2），下沉后数组变为 `[3, 9, 5, 1, 4, 2]`；  
  - 处理下标 1（值为 9），无需下沉；  
  - 处理下标 0（值为 3），下沉后数组变为 `[9, 4, 5, 1, 3, 2]`，建堆完成。  

- **时间复杂度**：O(N)（看似 O(N logN)，实际推导可简化为 O(N)）。  


### 18. 设计一个排行榜的数据结构，说思路  
设计排行榜需支持**高效的插入、更新、查询前 N 名**操作，核心思路如下：  

1. **底层数据结构选择**：  
   - 主结构：**跳跃表（Skiplist）** 或 **平衡二叉搜索树（如红黑树）**，按分数排序，支持 O(logN) 级的插入、删除、更新。  
   - 辅助结构：**哈希表**，映射用户 ID 到分数和跳跃表节点，支持 O(1) 级的用户分数查询和更新。  

2. **核心功能实现**：  
   - **添加/更新用户分数**：  
     1. 从哈希表查找用户是否存在，若存在则删除跳跃表中旧分数的节点；  
     2. 插入新分数到跳跃表（按分数排序，分数相同可按时间戳或用户 ID 二次排序）；  
     3. 更新哈希表中的用户分数和节点引用。  
   - **查询用户排名**：  
     1. 从哈希表获取用户分数对应的跳跃表节点；  
     2. 遍历跳跃表，统计比该节点分数高的节点数量，即为排名（跳跃表可记录前缀节点数优化此操作）。  
   - **查询前 N 名用户**：  
     1. 从跳跃表头部（最高分）开始遍历，取前 N 个节点；  
     2. 返回用户 ID 和分数列表。  

3. **优化点**：  
   - 分数可能重复，需支持按“分数降序 + 时间戳升序”排序（确保先达到该分数的用户排名靠前）；  
   - 若排行榜数据量大，可定期持久化到数据库，并缓存前 N 名减少查询开销；  
   - 支持分页查询（如第 11-20 名），跳跃表可通过索引快速定位范围。  

- **举例**：redis 的 `Sorted Set` 正是采用“跳跃表 + 哈希表”实现，可直接用于排行榜场景（`ZADD` 更新分数，`ZRANK` 查排名，`ZRANGE` 查前 N 名）。

### 19. 玩游戏吗，玩我们公司的游戏吗？
