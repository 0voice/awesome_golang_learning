## 拼多多
### 1. RPC 的整个调用过程  
RPC（远程过程调用）是跨进程/跨机器调用函数的协议，核心是“像调用本地函数一样调用远程函数”，完整流程如下：  

1. **客户端发起调用**：  
   客户端调用本地封装的“RPC stub（存根）”函数（如 `userService.GetUser(123)`），stub 负责将调用参数（如用户 ID=123）序列化为二进制数据（如 Protobuf、JSON）。  

2. **网络传输**：  
   客户端通过网络协议（如 TCP、HTTP/2）将序列化后的请求数据发送到服务端。  

3. **服务端接收请求**：  
   服务端的“RPC 服务端 stub”监听网络端口，接收请求数据后，反序列化为原始参数（如将二进制转成 `int 123`）。  

4. **服务端执行函数**：  
   服务端 stub 调用实际的业务函数（如 `GetUser` 方法），处理业务逻辑（如从数据库查询用户数据）。  

5. **服务端返回结果**：  
   业务函数执行完成后，服务端 stub 将结果（如用户信息）序列化，通过网络返回给客户端。  

6. **客户端接收结果**：  
   客户端 stub 接收响应数据，反序列化为原始结果，返回给客户端调用者，完成一次 RPC 调用。  

核心组件：stub（序列化/反序列化）、网络传输层（通信协议）、服务发现（定位服务端地址）。


### 2. 服务发现一般可以怎么做  
服务发现用于“客户端找到服务端的网络地址”，解决分布式系统中服务动态部署、地址变化的问题，常见方案：  

1. **基于注册中心的集中式方案**：  
   - 流程：服务启动时将地址（IP:Port）注册到注册中心（如 Nacos、Eureka、Consul）；客户端从注册中心订阅服务地址，定期更新本地缓存；服务下线时主动从注册中心注销。  
   - 优势：支持服务健康检查（注册中心剔除故障服务）、负载均衡（客户端从地址列表选一个调用）。  

2. **基于 DNS 的方案**：  
   - 流程：将服务名映射为 DNS 域名（如 `user-service.example.com`），DNS 服务器解析域名得到服务端 IP 列表；客户端通过 DNS 解析获取地址。  
   - 优势：无需额外部署注册中心，依赖现有 DNS 基础设施；缺点：不支持健康检查，地址更新有延迟。  

3. **基于配置文件的静态方案**：  
   - 流程：将服务端地址写在客户端配置文件中（如 `user_service_addr = 192.168.1.100:8080`），需手动更新配置。  
   - 优势：简单，适合服务地址固定的场景；缺点：不支持动态扩缩容，维护成本高。  

4. **基于服务网格的方案**：  
   - 流程：通过 Sidecar 代理（如 Istio 的 Envoy）拦截服务调用，Sidecar 从控制平面获取服务地址，客户端无需感知服务发现逻辑。  
   - 优势：解耦服务发现与业务代码，支持流量控制、监控；缺点：架构复杂，有性能开销。  


### 3. InnoDB 引擎的特性  
InnoDB 是 MySQL 默认的事务型存储引擎，核心特性围绕“事务安全、并发控制、性能优化”设计：  

1. **支持事务**：  
   遵循 ACID 特性，通过 redo log（重做日志）保证持久性，undo log（回滚日志）保证原子性和一致性，MVCC（多版本并发控制）保证隔离性。  

2. **行级锁**：  
   支持行级锁（`SELECT ... FOR UPDATE`）和表级锁，并发写操作时仅锁定修改的行，减少锁冲突，适合高并发写场景（如电商订单）。  

3. **聚簇索引**：  
   主键索引（聚簇索引）的叶子节点直接存储完整数据行，二级索引（如普通索引）的叶子节点存储主键值，查询时需通过主键回表（或覆盖索引避免回表）。  

4. **MVCC 多版本并发控制**：  
   通过隐藏列（`DB_TRX_ID` 事务 ID、`DB_ROLL_PTR` 回滚指针）和 undo log 维护数据历史版本，实现“可重复读”隔离级别，读写不阻塞（读不加锁，写不阻塞读）。  

5. **崩溃恢复**：  
   依赖 redo log 和 undo log，数据库崩溃后，通过 redo log 恢复已提交的事务，通过 undo log 回滚未提交的事务，保证数据一致性。  

6. **外键支持**：  
   支持外键约束（`FOREIGN KEY`），确保关联表数据的完整性（如订单表的 `user_id` 必须在用户表中存在）。  


### 4. MySQL 数据库支持高并发的读写，设计上有哪些可以用的方案？  
MySQL 支持高并发读写需从“架构优化、存储优化、查询优化”多维度设计，核心方案：  

1. **读写分离**：  
   - 架构：主库负责写操作（`INSERT/UPDATE/DELETE`），从库负责读操作（`SELECT`），主库通过 binlog 同步数据到从库。  
   - 优势：分散读压力（读请求通常远多于写请求），支持水平扩展从库数量；工具：MHA、Orchestrator 自动管理主从同步。  

2. **分库分表**：  
   - 水平分表（按行拆分）：如按用户 ID 哈希分表（`user_id % 10` 分 10 张表），或按时间分表（`order_202401`、`order_202402`），降低单表数据量（避免超千万级）。  
   - 垂直分表（按列拆分）：将大表拆分为“高频字段表”（如 `user_base` 存 ID/name/phone）和“低频字段表”（如 `user_ext` 存 avatar/desc），减少行大小，提升索引效率。  
   - 工具：ShardingSphere、MyCat 实现分库分表路由。  

3. **索引优化**：  
   - 为高频查询字段建索引（如 `WHERE`、`JOIN`、`ORDER BY` 后的字段），避免全表扫描；联合索引遵循“最左前缀原则”，减少回表。  
   - 避免过度索引（写入时需维护索引，影响性能），定期用 `EXPLAIN` 分析慢查询，优化索引。  

4. **缓存层引入**：  
   - 多级缓存：本地缓存（如 Caffeine）+ 分布式缓存（如 Redis），热点数据（如商品详情、用户信息）优先走缓存，减少数据库访问。  
   - 缓存策略：Cache-Aside（读走缓存，写更数据库后删缓存），避免缓存与数据库不一致。  

5. **数据库配置优化**：  
   - 内存配置：调大 `innodb_buffer_pool_size`（建议物理内存的 50%-70%），提高数据缓存命中率，减少磁盘 IO。  
   - 连接池：使用数据库连接池（如 HikariCP、Go 的 `database/sql`）复用连接，避免频繁创建销毁连接的开销，控制并发连接数（`max_connections`）。  

6. **事务与锁优化**：  
   - 短事务优先：避免长事务占用锁资源，减少锁等待；用 `READ COMMITTED` 隔离级别（比 `REPEATABLE READ` 并发更高）。  
   - 批量操作：将多次小写入合并为批量写入（如 `INSERT INTO ... VALUES (...), (...), (...)`），减少事务提交次数。  


### 5. 了解哪些缓存淘汰策略？  
缓存淘汰策略是“当缓存容量满时，删除部分数据以腾出空间”的规则，常见策略：  

1. **LRU（Least Recently Used，最近最少使用）**：  
   - 原理：删除最久未被访问的数据（认为久未访问的数据未来被访问的概率低）。  
   - 实现：用链表+哈希表记录访问顺序，新访问/更新的数据移到链表头部，满时删除链表尾部数据；Redis 近似 LRU（采样淘汰）。  

2. **LFU（Least Frequently Used，最不经常使用）**：  
   - 原理：删除访问频率最低的数据（认为访问次数少的数据未来被访问的概率低）。  
   - 实现：为每个数据记录访问次数，满时删除次数最少的数据；适合访问频率稳定的场景（如热点数据长期被访问）。  

3. **FIFO（First In First Out，先进先出）**：  
   - 原理：按数据进入缓存的顺序淘汰，先进入的先删除（不考虑访问频率和时间）。  
   - 优势：实现简单（用队列）；缺点：无法识别热点数据（如刚进入的非热点数据可能淘汰掉之前的热点数据）。  

4. **ARC（Adaptive Replacement Cache，自适应替换缓存）**：  
   - 原理：结合 LRU 和 LFU，维护两个缓存列表（LRU 列表和 LFU 列表），根据访问模式动态调整两个列表的大小，平衡“最近访问”和“频繁访问”。  
   - 优势：自适应不同访问场景，命中率高于 LRU/LFU；缺点：实现复杂。  

5. **TTL（Time To Live，存活时间）**：  
   - 原理：为每个数据设置过期时间，到期后自动删除，不考虑访问情况。  
   - 应用：Redis 缓存默认策略，适合数据有明确有效期的场景（如会话数据、临时令牌）。  


### 6. LRU-K 和 LRU 的区别  
LRU-K 是 LRU 的改进版，核心区别是“判断‘淘汰候选’的依据从‘最近1次访问’变为‘最近K次访问’”，避免 LRU 的“缓存污染”问题：  

| 维度         | LRU（K=1）                    | LRU-K（如 K=2）                 |
|--------------|--------------------------------|--------------------------------|
| **淘汰依据** | 最久未被访问过（仅看最近1次访问时间） | 最久未达到 K 次访问（需积累 K 次访问才进入主缓存） |
| **缓存结构** | 单一层缓存（所有数据在同一缓存区） | 两层缓存：候选缓存（记录访问次数）+ 主缓存（LRU 管理） |
| **抗污染能力** | 弱（如一次性访问的“冷数据”会淘汰掉热点数据） | 强（冷数据需积累 K 次访问才进入主缓存，避免污染） |
| **实现复杂度** | 简单（链表+哈希表）              | 复杂（需维护访问次数、候选缓存） |

**示例**：  
- LRU：用户一次性访问 100 个冷数据，会将缓存中已有的 100 个热点数据全部淘汰，导致后续热点访问命中率骤降。  
- LRU-2：冷数据需被访问 2 次才进入主缓存，一次性访问的冷数据仅进入候选缓存，不会淘汰主缓存的热点数据，抗污染能力更强。  

应用场景：LRU 适合访问模式稳定的场景；LRU-K 适合存在大量一次性冷数据的场景（如网页缓存、日志缓存）。


### 7. Go 的 defer 机制  
Go 的 `defer` 用于“延迟执行函数调用”，确保函数在当前函数返回前（无论正常返回还是 panic）执行，核心特性：  

1. **执行时机**：  
   - `defer` 声明的函数会被压入“defer 栈”，当前函数执行到 `return` 时，按“后进先出（LIFO）”顺序执行栈中的 defer 函数。  
   - 即使函数发生 `panic`，defer 函数仍会执行（可用于资源释放，避免泄漏）。  

2. **参数预计算**：  
   - `defer` 函数的参数在声明时就会计算，而非执行时计算。  
   - 示例：  
     ```go
     func f() {
         x := 1
         defer fmt.Println(x) // 声明时 x=1，参数已确定
         x = 2
         return // 执行 defer 打印 1，而非 2
     }
     ```  

3. **常见用途**：  
   - 资源释放：关闭文件（`defer file.Close()`）、解锁（`defer mu.Unlock()`）、释放连接（`defer conn.Close()`）。  
   - 异常捕获：在 defer 中通过 `recover()` 捕获 `panic`，避免程序崩溃。  

4. **注意事项**：  
   - 避免在循环中使用 defer（如循环打开文件并 defer 关闭，会导致大量文件句柄未及时释放，需手动控制）。  
   - defer 函数执行顺序与声明顺序相反（如声明 defer A、defer B，返回时先执行 B，再执行 A）。  


### 8. Go 的 map 是有序还是无序？为什么？  
Go 的原生 `map` 是**无序的**，且 Go 1.0 到 Go 1.21 均未保证遍历顺序的稳定性，核心原因是**底层哈希表的实现机制**：  

1. **底层结构导致无序**：  
   - Go 的 map 基于哈希表实现，键（key）通过哈希函数计算后映射到不同的“桶（bucket）”，桶内元素再通过链表或数组存储。  
   - 遍历 map 时，会从随机的桶开始遍历（Go 1.12+ 引入随机起始桶，避免依赖遍历顺序的错误代码），桶内元素的顺序也不固定（哈希冲突时的存储顺序与插入顺序无关），因此遍历结果无序。  

2. **设计意图**：  
   - Go 团队不希望开发者依赖 map 的遍历顺序，避免因底层实现变化导致程序出错；若需有序遍历，需手动将键或键值对存入切片（`slice`），再对切片排序。  

**示例**：  
```go
m := map[string]int{"a":1, "b":2, "c":3}
for k, v := range m {
    fmt.Println(k, v) // 每次运行输出顺序可能不同（如 a→c→b 或 b→a→c）
}

// 有序遍历的实现：将键存入切片并排序
keys := make([]string, 0, len(m))
for k := range m {
    keys = append(keys, k)
}
sort.Strings(keys) // 对键排序
for _, k := range keys {
    fmt.Println(k, m[k]) // 按 a→b→c 顺序输出
}
```  


### 9. GET、POST 的区别  
GET 和 POST 是 HTTP 中最常用的两种请求方法，核心区别集中在**用途、数据传输、安全性、幂等性**：  

| 维度         | GET                            | POST                           |
|--------------|--------------------------------|--------------------------------|
| **核心用途** | 获取资源（无副作用，如查询数据） | 提交资源（有副作用，如创建/修改数据） |
| **数据位置** | 数据通过 URL 参数传递（可见，长度受浏览器限制） | 数据通过请求体（Body）传递（不可见，长度无限制） |
| **缓存**     | 可被浏览器缓存（如刷新页面不重新请求） | 默认不缓存（需手动设置 `Cache-Control`） |
| **幂等性**   | 幂等（多次请求结果一致，不改变服务器状态） | 非幂等（多次请求可能重复提交，如创建多个订单） |
| **安全性**   | 数据明文暴露在 URL 中（适合非敏感数据） | 数据在请求体中（相对安全，仍需 HTTPS 加密敏感数据） |
| **浏览器回退** | 回退无提示（缓存生效）          | 回退提示“是否重新提交”（避免重复操作） |  


### 10. HTTP 是无状态的，如何做到有状态？（cookie session）  
HTTP 无状态指“每次请求都是独立的，服务器不记得之前的请求”，实现有状态需通过**客户端存储（Cookie）** 或**服务器存储（Session）** 记录上下文：  

#### 1. Cookie 方案  
- **原理**：服务器在响应头中通过 `Set-Cookie` 字段，将状态数据（如用户 ID、会话标识）发送给客户端；客户端将 Cookie 保存在本地（如浏览器缓存），后续请求时自动在请求头中携带 `Cookie` 字段，服务器通过 Cookie 识别用户。  
- **示例**：  
  - 服务器响应头：`Set-Cookie: session_id=abc123; Path=/; HttpOnly`  
  - 客户端后续请求头：`Cookie: session_id=abc123`  
- **特点**：存储在客户端（大小限制约 4KB），安全性低（可被篡改，需加 `HttpOnly` 防止 JS 读取，`Secure` 限制 HTTPS 传输）。  

#### 2. Session 方案  
- **原理**：服务器为每个用户创建“会话（Session）”，生成唯一的 Session ID（如 `abc123`）；服务器将 Session 数据（如用户信息、权限）存储在本地（内存、Redis、数据库），并通过 Cookie 将 Session ID 发送给客户端；客户端后续请求携带 Session ID，服务器通过 ID 查询 Session 数据，识别用户状态。  
- **示例**：  
  - 服务器创建 Session：`session_id=abc123` → 存储 `{"user_id":123, "name":"Alice"}`  
  - 客户端携带 Session ID → 服务器查询 Session 数据，确认用户身份。  
- **特点**：状态数据存储在服务器（安全，可存大量数据），依赖 Cookie 传递 Session ID（无 Cookie 时可通过 URL 参数传递，但不安全）。  

#### 3. 其他方案  
- **Token 方案**：服务器生成加密 Token（如 JWT），包含用户状态信息，客户端存储 Token（Cookie、LocalStorage），后续请求携带 Token，服务器解密 Token 即可获取状态（无需服务器存储 Session，适合分布式系统）。  


### 11. HTTPS 过程  
HTTPS 是“HTTP + TLS/SSL”的加密通信协议，核心是通过 TLS 握手建立安全连接，再传输 HTTP 数据，完整过程：  

1. **客户端发起 TLS 握手（Client Hello）**：  
   - 客户端向服务器发送：支持的 TLS 版本（如 TLS 1.3）、加密套件（如 AES-GCM-SHA256）、随机数 `ClientRandom`、客户端支持的压缩算法。  

2. **服务器响应（Server Hello）**：  
   - 服务器选择双方兼容的 TLS 版本和加密套件，返回：服务器证书（含公钥）、随机数 `ServerRandom`、服务器Hello Done 消息。  

3. **客户端验证证书与生成预主密钥**：  
   - 客户端用操作系统/浏览器内置的 CA 根证书验证服务器证书（确认服务器身份，防止伪造）。  
   - 客户端生成“预主密钥（PreMasterSecret）”，用服务器证书中的公钥加密 PreMasterSecret，发送给服务器。  

4. **服务器生成主密钥**：  
   - 服务器用自身私钥解密 PreMasterSecret，得到 PreMasterSecret。  
   - 客户端和服务器分别基于 `ClientRandom`、`ServerRandom`、`PreMasterSecret`，通过相同的密钥派生算法（如 HKDF）生成“主密钥（MasterSecret）”。  

5. **握手完成，加密通信**：  
   - 客户端发送“Change Cipher Spec”消息，告知服务器后续数据用主密钥加密；同时发送“Finished”消息（用主密钥加密的握手摘要，验证握手完整性）。  
   - 服务器接收后，同样发送“Change Cipher Spec”和“Finished”消息，双方确认握手成功。  
   - 后续 HTTP 数据通过主密钥衍生的会话密钥加密传输（对称加密，效率高），同时用 MAC 算法验证数据完整性，防止篡改。  

核心保障：加密（防止数据窃听）、认证（防止服务器伪造）、完整性（防止数据篡改）。

### 12. TCP 四次挥手
TCP 四次挥手是 **TCP 连接关闭** 的标准流程，用于确保双方都完成数据传输并释放资源，流程如下（以“客户端主动关闭，服务端被动关闭”为例）：  

1. **第一次挥手（客户端 → 服务端：FIN）**  
   客户端完成数据发送后，向服务端发送 `FIN`（Finish）报文，请求关闭连接，客户端进入 **FIN_WAIT_1** 状态（等待服务端的 ACK 响应）。  

2. **第二次挥手（服务端 → 客户端：ACK）**  
   服务端收到 `FIN` 后，立即返回 `ACK`（确认）报文，告知客户端“已收到关闭请求”，服务端进入 **CLOSE_WAIT** 状态（此时服务端可能仍在发送未完成的数据）；客户端收到 ACK 后，进入 **FIN_WAIT_2** 状态（等待服务端的 FIN 报文）。  

3. **第三次挥手（服务端 → 客户端：FIN）**  
   服务端完成剩余数据发送后，向客户端发送 `FIN` 报文，请求关闭连接，服务端进入 **LAST_ACK** 状态（等待客户端的 ACK 响应）。  

4. **第四次挥手（客户端 → 服务端：ACK）**  
   客户端收到 `FIN` 后，返回 `ACK` 报文，告知服务端“已收到关闭请求”，客户端进入 **TIME_WAIT** 状态（等待 2MSL 后彻底关闭）；服务端收到 ACK 后，立即进入 **CLOSED** 状态，释放资源。  


### 13. 如果客户端发了 FIN 包过去，但是服务端一直不回包会怎样？
客户端发送 `FIN` 包后，若服务端未返回 `ACK`（如网络丢包、服务端故障），客户端会触发 **TCP 超时重传机制**，具体过程：  

1. **初始超时等待**：客户端进入 `FIN_WAIT_1` 状态，启动超时计时器（初始超时时间通常为 1 秒）。  
2. **超时重传**：若超时时间内未收到服务端的 `ACK`，客户端会重传 `FIN` 包，并将超时时间 **翻倍**（如 1s → 2s → 4s → 8s...）。  
3. **重传次数限制**：TCP 会限制重传次数（通常为 5 次，总超时约 30-60 秒），若所有重传均失败：  
   - 客户端判定服务端不可达，主动释放连接，退出 `FIN_WAIT_1` 状态，进入 `CLOSED` 状态。  
   - 若服务端后续恢复并发送 `ACK`，因客户端已关闭连接，会直接丢弃该 `ACK`。  


### 14. 如果客户端发了 FIN 包过去，服务端一直不回包，在客户端是一个什么样的状态？
客户端发送 `FIN` 包后，若服务端一直不回 `ACK`，客户端的状态和 `netstat` 显示如下：  

1. **客户端内核状态**：  
   客户端始终处于 **FIN_WAIT_1** 状态（而非阻塞）—— 该状态是 TCP 协议定义的标准连接状态，用于表示“已发送 FIN，等待 ACK”，并非进程层面的“阻塞”（进程可正常处理其他任务，仅该连接的关闭流程处于等待）。  

2. **netstat 命令显示**：  
   执行 `netstat -an | grep 客户端端口` 时，会显示该连接的状态为 **FIN_WAIT1**（不同系统可能简写为 `FIN_WAIT1`），示例输出：  
   ```
   tcp        0      0  192.168.1.100:54321    192.168.1.200:8080     FIN_WAIT1   0          0
   ```  
   其中 `FIN_WAIT1` 明确标识客户端当前的连接状态，直至超时重传失败后，状态才会转为 `CLOSED` 并从列表中消失。  


### 15. 丢包重传的影响
TCP 丢包后，为避免网络拥塞加剧，会通过 **拥塞控制算法** 调整发送速率，核心影响如下：  

1. **超时重传的影响（重度丢包）**：  
   - 若因超时触发重传（判定为“网络拥塞”），TCP 会执行：  
     1. **慢启动阈值（ssthresh）减半**：将当前拥塞窗口（cwnd）的一半设为新的 ssthresh（如 cwnd=16 → ssthresh=8），减少后续发送速率的上限。  
     2. **重新进入慢启动**：将 cwnd 重置为 1，按“指数增长”方式恢复发送（1→2→4→8...），直至 cwnd 达到新的 ssthresh，再进入“线性增长”的拥塞避免阶段。  
   - 影响：发送速率大幅下降，恢复速度慢，适合网络严重拥塞场景。  

2. **快速重传的影响（轻度丢包）**：  
   - 若收到 3 个重复 ACK 触发重传（判定为“个别包丢失，网络未拥塞”），TCP 会执行：  
     1. **ssthresh 减半**：与超时重传一致，控制后续速率上限。  
     2. **cwnd 设为 ssthresh**：跳过慢启动，直接进入拥塞避免阶段（cwnd 按“线性增长”恢复）。  
   - 影响：发送速率小幅下降，恢复速度快，减少对正常传输的干扰。  

3. **滑动窗口的间接影响**：  
   丢包可能导致服务端接收窗口（rwnd）变小（如服务端缓冲区满，无法接收更多数据），客户端会根据 rwnd 动态调整发送窗口（发送窗口 = min(cwnd, rwnd)），进一步限制发送速率，避免数据堆积。  


### 16. Go 如何排障？  
Go 程序排障需结合 **日志、性能分析、调试工具**，覆盖“运行时异常、性能瓶颈、并发问题”等场景，核心方法：  

#### 1. 基础排障：日志与错误捕获  
- **结构化日志**：使用 `zap`、`logrus` 等库记录关键流程（如请求参数、返回结果、错误信息），包含时间戳、日志级别、goroutine ID，便于定位问题上下文。  
- **panic 捕获**：在主函数或关键 goroutine 中用 `recover()` 捕获 `panic`，打印堆栈信息（`debug.Stack()`），避免程序直接崩溃，示例：  
  ```go
  defer func() {
      if err := recover(); err != nil {
          fmt.Printf("panic recovered: %v\nstack: %s", err, debug.Stack())
      }
  }()
  ```  

#### 2. 性能排障：pprof 分析  
Go 内置 `pprof` 工具，用于分析 **CPU、内存、goroutine 阻塞** 等性能问题：  
- **HTTP 方式（线上常用）**：  
  1. 代码中导入 `_ "net/http/pprof"`，启动 HTTP 服务（默认端口 6060）。  
  2. 通过命令采集数据：  
     - CPU 分析：`go tool pprof http://localhost:6060/debug/pprof/profile?seconds=30`（采集 30 秒 CPU 数据，生成火焰图定位热点函数）。  
     - 内存分析：`go tool pprof http://localhost:6060/debug/pprof/heap`（分析内存泄漏、大对象分配）。  
     - goroutine 分析：`go tool pprof http://localhost:6060/debug/pprof/goroutine?debug=2`（查看 goroutine 堆栈，定位死锁、阻塞）。  

#### 3. 并发问题排障：race 检测与死锁工具  
- **数据竞争检测**：编译时添加 `-race` 选项（如 `go run -race main.go`），运行时检测多 goroutine 对共享变量的非安全访问，打印竞争位置。  
- **死锁检测**：使用 `go-deadlock` 库（替换标准库 `sync` 的锁），死锁时自动打印所有 goroutine 的堆栈信息，快速定位循环等待的锁。  

#### 4. 线上排障：日志聚合与监控  
- 日志聚合：将分布式节点的日志收集到 ELK（Elasticsearch+Logstash+Kibana）或 Loki，通过关键词检索、时间范围筛选快速定位跨节点问题。  
- 监控告警：用 Prometheus 采集指标（如 goroutine 数量、内存使用、接口响应时间），Grafana 可视化，配置阈值告警（如 goroutine 数突增时触发告警）。  


### 17. 二叉树的中序遍历  
二叉树的中序遍历（In-order Traversal）是“**左子树 → 根节点 → 右子树**”的递归遍历规则，适用于二叉搜索树（BST）时，遍历结果为 **升序序列**。  

#### 1. 递归实现（简单直观）  
```go
type TreeNode struct {
    Val   int
    Left  *TreeNode
    Right *TreeNode
}

// 递归中序遍历，结果存入 slice
func inorderTraversal(root *TreeNode) []int {
    var res []int
    var traversal func(node *TreeNode)
    traversal = func(node *TreeNode) {
        if node == nil {
            return
        }
        traversal(node.Left)  // 遍历左子树
        res = append(res, node.Val)  // 访问根节点
        traversal(node.Right) // 遍历右子树
    }
    traversal(root)
    return res
}
```  

#### 2. 迭代实现（手动维护栈，避免递归栈溢出）  
```go
func inorderTraversalIterative(root *TreeNode) []int {
    var res []int
    var stack []*TreeNode // 用栈存储待访问的节点
    curr := root

    for curr != nil || len(stack) > 0 {
        // 1. 遍历左子树，所有左节点入栈
        for curr != nil {
            stack = append(stack, curr)
            curr = curr.Left
        }
        // 2. 弹出栈顶节点（根节点），访问其值
        curr = stack[len(stack)-1]
        stack = stack[:len(stack)-1]
        res = append(res, curr.Val)
        // 3. 遍历右子树
        curr = curr.Right
    }
    return res
}
```  

#### 3. 复杂度分析  
- **时间复杂度**：O(n)，每个节点访问一次（n 为节点总数）。  
- **空间复杂度**：O(h)，h 为树的高度（递归实现的递归栈、迭代实现的手动栈，均取决于树高；平衡树 h=logn，最坏情况（链状树）h=n）。

### 18. Golang 和 C++ 的区别（高频）
Golang 和 C++ 因设计目标差异，核心区别集中在内存管理、并发模型、语法复杂度与应用场景，具体如下：

| 维度         | Golang                          | C++                             |
|--------------|--------------------------------|--------------------------------|
| **内存管理** | 自动垃圾回收（GC），无需手动分配/释放，降低内存泄漏风险；仅需避免循环引用，无需关注底层内存细节 | 手动管理（`new`/`delete`/`malloc`/`free`），支持智能指针（`shared_ptr`）简化操作，但仍可能出现野指针、内存泄漏；灵活度高但对开发者要求高 |
| **并发模型** | 基于 Goroutine + Channel，轻量级并发（单 Goroutine 初始栈仅 2KB，支持百万级并发）；遵循 CSP 模型，“通信共享内存”，减少锁竞争 | 基于操作系统线程（`std::thread`），重量级并发（单线程栈通常 1-8MB，支持数千级并发）；需手动加锁（`std::mutex`）控制共享内存，易出现死锁 |
| **语法复杂度** | 语法简洁（仅 25 个关键字），无类继承、模板重载，通过“结构体+接口”实现多态；编译速度快，注重工程化效率 | 语法复杂，支持类继承、多态、模板、运算符重载；功能强大但灵活度过高，编译速度慢，需关注内存对齐、析构顺序等底层细节 |
| **执行效率** | 编译型语言，效率接近 C++（约为 C++ 的 70%-90%）；GC 有微秒级 STW 延迟（Go 1.19+ 已优化），满足多数后端场景 | 执行效率接近机器码，无 GC 开销；适合对性能极致要求的场景（游戏引擎、数据库内核、操作系统） |
| **生态与场景** | 擅长后端开发（微服务、分布式系统）、云原生领域（K8s、Etcd 均为 Go 编写）；生态工具统一（`pprof`、`gofmt`） | 擅长高性能场景（图形渲染、嵌入式开发、高频交易）、底层开发；生态覆盖广但碎片化较严重 |


### 19. Golang 的内存回收机制
Golang 的垃圾回收（GC）是自动内存管理机制，核心目标是回收堆中不再引用的内存，兼顾效率与低延迟，核心设计如下：

#### 1. 核心算法：标记-清除-整理（Mark-Sweep-Compact）
- **标记阶段**：从“根对象”（全局变量、栈上变量、寄存器指向对象）出发，遍历堆中可达对象，通过 `bitmap` 标记“存活状态”；该阶段与用户代码**并发执行**，仅初始“根扫描”和最终“重新标记”需短暂 STW（微秒级）。  
- **清除阶段**：遍历堆内存，回收未标记的“垃圾对象”，将空闲内存块存入空闲链表，供后续分配使用。  
- **整理阶段**：针对小对象区域（`arena` 中 <32KB 的对象），将存活对象紧凑排列，减少内存碎片；大对象区域因碎片影响小，通常不整理。

#### 2. 关键优化特性
- **三色标记法**：用“白色（未标记）、灰色（待标记）、黑色（已标记）”标记对象，配合写屏障（Write Barrier）跟踪并发修改，避免漏标。  
- **分代回收（Go 1.19+）**：将堆分为“年轻代”（新创建对象，回收频率高）和“老年代”（长期存活对象，回收频率低），减少整体回收开销。  
- **并发回收**：标记、清除阶段均与 Goroutine 并发执行，STW 延迟极低（Go 1.21+ 通常 <100 微秒），对业务影响小。

#### 3. 触发时机
- **内存阈值触发**：堆内存增长至“上次回收后堆大小的 2 倍”（默认阈值）时触发。  
- **定时触发**：若长期未达阈值，每 2 分钟强制触发一次，避免内存泄漏累积。  
- **手动触发**：通过 `runtime.GC()` 手动调用，仅推荐用于测试场景，不建议线上使用。


### 20. 协程和线程的区别
协程（以 Golang Goroutine 为例）和操作系统线程均为并发单元，但在调度、资源、并发能力上差异显著：

| 维度         | 协程（Goroutine）               | 线程（操作系统线程）            |
|--------------|--------------------------------|--------------------------------|
| **调度主体** | 用户态调度（Go 运行时 GMP 调度器）；无需内核参与，调度开销低（几纳秒） | 内核态调度（操作系统内核）；调度需切换内核态/用户态，开销高（几微秒） |
| **资源占用** | 初始栈 2KB，可动态扩容（最大 1GB）；无独立内核数据结构（如 TCB、页表） | 初始栈 1-8MB，不可动态调整；需占用内核资源（TCB、页表），内存消耗高 |
| **并发能力** | 支持百万级并发：单机器可运行数万至数百万个协程，无明显性能下降 | 支持数千级并发：线程数超内核限制（通常数千）后，上下文切换频繁，CPU 利用率下降 |
| **上下文切换** | 轻量切换：仅保存程序计数器、栈指针等少量信息，无需切换页表 | 重量级切换：需保存寄存器、栈、页表等完整上下文，切换成本是协程的 100-1000 倍 |
| **依赖关系** | 多协程共享 1 个线程（M）；协程阻塞（如 I/O）时，GMP 调度器会将线程分配给其他就绪协程，避免线程空闲 | 线程独立运行；线程阻塞时，内核调度其他线程，但线程本身无法复用 |

有过 Golang 服务的性能压测经验，协程数量与 CPU 使用率是否稳定，核心取决于 **协程的业务逻辑（I/O 密集/CPU 密集）** 和 **机器硬件资源**，没有固定阈值，但有明确的场景化规律：

### 1. 轻量 I/O 型协程（最常见场景）
若协程逻辑以 I/O 操作为主（如 HTTP 接口调用、数据库查询、Redis 访问），特点是“大部分时间在等待 I/O 响应，CPU 空闲”：
- **压测现象**：在 4C8G 标准机器上，协程数量从 1 万增至 200 万时，CPU 使用率增长平缓（通常维持在 30%-80%），无明显不稳定。  
  例如：单协程处理一次 HTTP 请求（含 1 次 MySQL 查询），200 万协程并发时，CPU 主要消耗在“协程调度”和“I/O 结果处理”，因多数协程处于 I/O 等待状态，不会导致 CPU 过载。
- **不稳定临界点**：通常在 **300 万+ 协程** 时，可能因“协程调度开销累积”（如 GMP 调度器的 P 与 M 绑定切换频繁），出现 CPU 使用率波动（±10% 左右），但核心瓶颈仍是网络/I/O 带宽，而非协程本身。

### 2. CPU 密集型协程（特殊场景）
若协程逻辑以 CPU 计算为主（如循环累加、加密解密、数据序列化），特点是“协程持续占用 CPU，无 I/O 等待”：
- **压测现象**：协程数量超过 **CPU 核心数的 10-20 倍** 时，CPU 使用率会快速拉满至 100%，且开始不稳定。  
  例如：4C 机器上，40-80 个 CPU 密集型协程并发时，CPU 已饱和；超过 100 个协程后，会因“频繁上下文切换”（Goroutine 切换虽轻量，但 CPU 密集场景下无空闲时间），导致 **CPU 使用率维持 100% 但吞吐量不增反降**，响应延迟大幅波动（如从 1ms 增至 100ms+）。
- **本质原因**：CPU 密集场景下，协程数量超过 CPU 核心数后，多协程需“抢占 CPU 时间片”，调度开销抵消了并发收益，导致 CPU 使用率看似满负荷，实际有效计算效率下降。

### 3. 压测工具与关键监控指标
- **工具**：用 `wrk`/`ghz` 压测 HTTP/gRPC 服务，用 `go test -bench` 压测单机函数，配合 `prometheus + grafana` 监控核心指标；
- **关键指标**：除 CPU 使用率外，需关注 **协程调度延迟**（通过 `pprof` 的 `sched` 模块查看）和 **GC 停顿时间**（避免大量协程创建/销毁触发频繁 GC，间接导致 CPU 波动）。

综上：轻量 I/O 场景下，百万级协程仍能保持 CPU 稳定；CPU 密集场景下，协程数接近 CPU 核心数的 10 倍时，CPU 会进入不稳定状态。

### 21. 你觉得之前工作中的服务，还可以怎么优化？（代码、架构、稳定性、流程）
### 22. 有没有对比过不同 RPC 框架的优缺点
### 23. 平时有没有登到机器上去看日志
### 24. 做过哪些觉得很厉害的事，参加过的比赛？
### 25. 实习期间的一些收获
### 26. 如何阅读大型项目的源码？
### 27. 有没有读过一些很惊艳的代码？
### 28. 你觉得自己有哪些不足？之后准备如何提升？
### 29. 你一定在面试很多公司，你如何看待拼多多的机会？
