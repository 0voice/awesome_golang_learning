## 滴滴
### 1. golang多态 底层源码哪里用到了
Go 多态基于接口实现，底层通过 `iface` 结构体（非空接口）和 `itab` 类型匹配表实现动态绑定。  
源码中典型应用：  
- `encoding/json` 包：序列化时通过接口 `json.Marshaler` 调用不同类型的 `MarshalJSON` 方法；  
- `io` 包：`io.Reader` 接口的 `Read` 方法，在文件、网络连接等不同实现中表现出不同行为；  
- `fmt` 包：`fmt.Print` 依赖 `Stringer` 接口，不同类型通过 `String()` 方法自定义输出格式。  


### 2. 设计一个hashmap
思路：  
1. **底层结构**：数组（桶）+ 链表（解决哈希冲突），桶中存储键值对节点；  
2. **哈希函数**：将 key 映射为数组索引，尽量分散分布；  
3. **核心操作**：  
   - 插入（Set）：计算索引，查找桶中是否有相同 key，有则更新，无则新增节点；  
   - 查询（Get）：计算索引，遍历对应桶的链表查找 key；  
   - 删除（Delete）：计算索引，遍历链表找到节点并移除；  
4. **优化**：加入负载因子（元素数/桶数），超过阈值时扩容（桶数翻倍），减少哈希冲突；  
5. **并发安全**：加互斥锁保护读写操作。  


### 3. redis分布式锁如何实现看门狗
思路：  
1. **获取锁**：用 `SET key uuid NX PX 30000` 命令，设置带过期时间（如30s）的唯一锁标识；  
2. **启动看门狗**：获取锁成功后，启动后台协程，每隔10s（小于过期时间）执行续约；  
3. **原子续约**：通过 Lua 脚本 `if redis.call('get', key) == uuid then redis.call('expire', key, 30) end` 验证锁归属并续期；  
4. **释放锁**：任务完成后，停止看门狗协程，用 Lua 脚本删除锁（校验 uuid 避免误删）；  
5. **异常处理**：若持有锁的协程崩溃，看门狗随协程退出，锁到期自动释放。  


### 4. 如何实现20个任务，最大协程数5，快速执行，且能够优雅关闭
思路：  
1. **控制并发**：用带缓冲的 channel 作为信号量（容量5），限制同时运行的协程数；  
2. **任务分发**：将20个任务放入任务队列，启动5个工作协程从队列取任务执行；  
3. **优雅关闭**：  
   - 用 `context.WithCancel` 创建可取消上下文，传递给工作协程；  
   - 收到关闭信号（如 Ctrl+C）时调用 cancel，工作协程退出；  
4. **等待完成**：用 `sync.WaitGroup` 等待所有任务执行完毕，确保资源正确释放。  


### 5. mysql死锁如何发生
死锁是两个或多个事务相互持有对方需要的锁，且都不释放已持有的锁，导致循环等待。  
常见场景：  
1. **交叉更新**：事务1更新行A后请求行B，事务2更新行B后请求行A；  
2. **不同索引顺序**：事务1按索引1加锁，事务2按索引2加锁，锁顺序不一致；  
3. **范围锁冲突**：事务1对范围 [1,10] 加锁，事务2对范围 [5,15] 加锁，相互等待对方释放重叠区域锁；  
4. **外键约束**：事务操作父子表时，加锁顺序相反导致循环等待。  
InnoDB 会检测死锁，自动回滚其中一个事务（代价较小的）解除阻塞。

### 6. 简单工厂和抽象工厂的区别？
- **简单工厂**：一个工厂类负责创建所有具体产品（如一个`ShapeFactory`创建圆形、方形），通过参数判断创建哪种产品，不遵循开闭原则（新增产品需修改工厂类）。  
- **抽象工厂**：多个抽象工厂类（如`ShapeFactory`、`ColorFactory`），每个工厂生产一族相关产品（如形状工厂生产圆形/方形，颜色工厂生产红/蓝），遵循开闭原则（新增产品族只需新增工厂类）。  


### 7. TCP粘包分包？
- **粘包**：多个小数据包被合并为一个大数据包发送（因Nagle算法或缓冲区未满）。  
- **分包**：一个大数据包被拆分为多个小数据包发送（因MTU限制）。  
- **解决**：通过固定长度、分隔符、协议头（含长度字段）等方式明确数据包边界。  


### 8. TCP与UDP的区别？
| 特性         | TCP                  | UDP                  |
|--------------|----------------------|----------------------|
| 连接性       | 面向连接（三次握手） | 无连接               |
| 可靠性       | 保证可靠（重传、排序等） | 不保证，尽最大努力交付 |
| 传输效率     | 低（开销大）         | 高（开销小）         |
| 适用场景     | 文件传输、HTTP等     | 视频通话、DNS等      |


### 9. TCP的头信息组成占用多少的字节？
TCP头部最小20字节（固定字段），最大60字节（含选项字段）。固定字段包括源端口、目的端口、序列号、确认号、数据偏移、控制位、窗口大小、校验和、紧急指针等。  


### 10. TCP可靠性传输通过什么保证？
- 校验和（检测数据损坏）；  
- 序列号与确认应答（确保数据有序且完整接收）；  
- 超时重传（未收到确认则重发）；  
- 流量控制（滑动窗口限制发送速率）；  
- 拥塞控制（避免网络过载）；  
- 连接管理（三次握手、四次挥手确保连接可靠建立与关闭）。  


### 11. 滑动窗口机制？
- 接收方通过窗口大小告知发送方可发送的数据量（字节数），控制发送速率（流量控制）。  
- 发送窗口：包含已发送未确认、可发送未发送、未允许发送三部分。  
- 接收窗口：包含已接收确认、可接收、未准备接收三部分。  
- 窗口滑动：接收方确认数据后，窗口向右移动，发送方根据新窗口调整发送。  


### 12. TCP为什么三次握手，两次不行？
- 三次握手确保双方收发能力正常：第一次握手验证发送方→接收方可达，第二次验证接收方→发送方可达，第三次确认双方均已知晓。  
- 两次握手可能导致：若旧连接请求延迟到达，接收方误认新连接并建立，发送方无响应，造成资源浪费。三次握手可通过序列号机制避免此问题。  


### 13. mysql中一张表有7条数据，id为1-7，现在删除最大两条，重启mysql，再插入一条数据，这个id是多少？
- 若id是自增主键且使用InnoDB引擎：自增ID值记录在内存中，重启后会从当前最大ID+1开始（删除后最大ID为5，重启插入后ID为6）。  
- 若使用MyISAM引擎：自增ID记录在表中，重启后仍从最大ID+1开始（结果同上）。  


### 14. ACID含义？
- **原子性（Atomicity）**：事务操作不可分割，要么全成，要么全败。  
- **一致性（Consistency）**：事务前后数据状态符合业务规则（如转账后总额不变）。  
- **隔离性（Isolation）**：并发事务相互隔离，避免干扰（如读未提交、读已提交等隔离级别）。  
- **持久性（Durability）**：事务提交后，数据永久保存（即使宕机也不丢失）。  


### 15. mysql左链接右链接内连接的区别？
- **内连接（INNER JOIN）**：只返回两表中匹配条件的记录。  
- **左连接（LEFT JOIN）**：返回左表所有记录，右表无匹配则补NULL。  
- **右连接（RIGHT JOIN）**：返回右表所有记录，左表无匹配则补NULL。  


### 16. 乐观锁和悲观锁？
- **悲观锁**：认为并发必然冲突，操作前加锁（如`SELECT ... FOR UPDATE`），阻塞其他操作，安全性高但性能低。  
- **乐观锁**：认为冲突概率低，不加锁直接操作，通过版本号或CAS校验冲突（如`UPDATE ... WHERE version = ?`），性能高但需处理重试。  


### 17. 怎么避免死锁？
- 统一加锁顺序（如按ID从小到大）；  
- 控制事务大小，缩短锁持有时间；  
- 避免在事务中同时操作多个表；  
- 用`SELECT ... FOR UPDATE SKIP LOCKED`跳过锁定行；  
- 定期检测死锁，设置事务超时。  


### 18. 分页和分段管理的区别？
| 特性         | 分页                  | 分段                  |
|--------------|----------------------|----------------------|
| 目的         | 提高内存利用率（固定大小） | 满足程序逻辑（按功能划分） |
| 大小         | 固定（如4KB）        | 不固定（按段内容）    |
| 地址结构     | 页号+页内偏移        | 段号+段内偏移        |
| 碎片         | 内部碎片（页内未用空间） | 外部碎片（段间空隙）  |


### 19. 操作系统内存偏高了，怎么分析？用到常用命令？
- **查看整体内存**：`free -h`（总内存、已用、空闲）、`top`/`htop`（动态查看进程内存占用）。  
- **定位高内存进程**：`ps aux --sort=-%mem | head -n 10`（按内存使用率排序）。  
- **分析进程内存**：`pmap -x <PID>`（进程内存映射）、`strace`（跟踪系统调用，看是否频繁分配内存）。  
- **内核内存分析**：`cat /proc/meminfo`（内核内存使用详情）。  


### 20. 一个文件，第9列有很多数字，统计一下前十的数字有哪些？
使用Linux命令组合：  
`awk '{print $9}' 文件名 | sort -n | uniq -c | sort -k1,1nr | head -n 10`  
- `awk '{print $9}'`：提取第9列；  
- `sort -n`：按数字排序；  
- `uniq -c`：统计每个数字出现次数；  
- `sort -k1,1nr`：按次数倒序排序；  
- `head -n 10`：取前10条。

### 21. 协程是怎么通信的
Go 中协程（goroutine）主要通过 channel 通信，遵循“不要通过共享内存通信，而要通过通信共享内存”的原则。此外，也可通过共享内存（如加锁的 map）通信，但 channel 是更推荐的方式。


### 22. 怎么用channel通信，举个例子
通过 channel 传递数据实现协程间同步或异步通信：
```go
func main() {
    ch := make(chan int) // 创建无缓冲channel
    go func() {
        ch <- 100 // 子协程发送数据
    }()
    num := <-ch // 主协程接收数据
    fmt.Println(num) // 输出：100
}
```
说明：子协程向 channel 发送数据，主协程从 channel 接收数据，实现同步通信。


### 23. 多个协程读写map会怎样
会触发 panic（程序崩溃）。Go 原生 map 不支持并发读写，运行时会检测到数据竞争并直接终止程序，属于“快速失败”机制，避免数据不一致。


### 24. 线程安全是什么意思
指多线程（或协程）并发访问共享资源时，无论线程调度顺序如何，程序都能保持正确的执行结果，不会出现数据不一致、逻辑错误等问题。实现线程安全通常需通过锁、原子操作等同步机制。


### 25. Redis缓存雪崩是什么
指在某一时间段，大量缓存 key 同时过期失效，或 Redis 服务宕机，导致所有请求直接落到数据库，造成数据库压力骤增，甚至宕机的现象。


### 26. 怎么解决缓存雪崩
- 过期时间错开：给 key 过期时间加随机值（如 `expire + rand(0, 300)`），避免同时失效；
- 缓存集群：部署 Redis 集群，避免单点故障；
- 服务降级：缓存失效时，返回默认值或限流，减轻数据库压力；
- 持久化：开启 RDB/AOF 持久化，Redis 重启后快速恢复缓存；
- 熔断机制：当数据库压力过大时，暂时停止访问，避免崩溃。


### 27. 将键的过期时间设置的太过分散会出现什么问题
- 可能导致缓存空间长期被无效数据占用（部分 key 过期时间过长），增加内存压力；
- 过期键清理（如惰性删除、定期删除）的效率降低，因为过期时间分布太散，难以批量处理；
- 极端情况下，若大量 key 过期时间被设置为极长，可能导致内存溢出。


### 28. 慢sql如何排查
- 开启 MySQL 慢查询日志：配置 `slow_query_log = 1`、`long_query_time = 1`（记录执行时间超过1秒的SQL）；
- 查看慢查询日志：通过 `mysqldumpslow` 工具分析（如 `mysqldumpslow -s t -t 10 slow.log` 取top10慢查询）；
- 实时查看：使用 `show processlist` 查看当前运行的SQL，定位阻塞或耗时语句；
- 执行计划分析：对可疑SQL执行 `explain`，查看是否使用索引、扫描行数等。


### 29. 确定问题后怎么解决
- 优化索引：为查询字段添加合适索引（如联合索引），避免全表扫描；
- 改写SQL：简化子查询、避免 `select *`、拆分复杂SQL；
- 表结构优化：分表（水平/垂直分表）、增加中间表减少联表查询；
- 缓存结果：将高频查询结果缓存到Redis，减少数据库访问；
- 调整参数：优化MySQL配置（如 `innodb_buffer_pool_size`、`join_buffer_size`）；
- 避免锁冲突：减少长事务，避免在事务中执行耗时操作。

### 30. 索引失效的原因？
- 查询条件中使用函数或表达式操作索引列（如 `SUBSTR(name, 1)`、`age + 1 = 10`）；
- 使用不等于（`!=`、`<>`）、`NOT IN`、`IS NOT NULL` 等操作符（可能导致全表扫描）；
- 联合索引不满足最左前缀原则（如联合索引 `(a,b,c)`，仅用 `b` 或 `c` 作为条件）；
- 字符串索引列使用数字查询（如 `name = 123`，导致隐式类型转换）；
- `LIKE` 以通配符开头（如 `LIKE '%abc'`）；
- 使用 `OR` 连接的条件中，部分字段无索引；
- 索引列存在大量重复值（选择性低，优化器可能放弃使用索引）。


### 31. 数字类型的索引，若是等于字符串，那么会走索引么？
不会。数字类型索引列与字符串比较时，MySQL 会对索引列进行隐式类型转换（将数字转为字符串），相当于对索引列使用函数操作，导致索引失效，会走全表扫描。  
例：`WHERE id = '123'`（`id` 为 int 类型），索引失效。


### 32. 写sql：一张订单表order，字段有订单id：orderId，用户id：userId，时间：time，查出所有用户的最新的一个订单信息？
```sql
-- 方法1：子查询获取每个用户的最新时间，再关联原表
SELECT o.*
FROM `order` o
INNER JOIN (
    SELECT userId, MAX(time) AS latest_time
    FROM `order`
    GROUP BY userId
) t ON o.userId = t.userId AND o.time = t.latest_time;

-- 方法2：窗口函数（MySQL 8.0+）
SELECT orderId, userId, time
FROM (
    SELECT 
        *, 
        ROW_NUMBER() OVER (PARTITION BY userId ORDER BY time DESC) AS rn
    FROM `order`
) t
WHERE rn = 1;
```


### 33. 项目中出现了网络异常，如何排查和解决？比如 connection cancel？
- **排查步骤**：  
  1. 查看应用日志，确认异常发生时间和上下文（如请求URL、参数）；  
  2. 检查网络链路：用 `ping` 测试主机连通性，`traceroute` 查看路由跳转，`netstat`/`ss` 查看连接状态；  
  3. 分析服务端状态：查看服务端日志是否有超时、过载记录，检查服务器负载（`top`）、端口监听（`netstat -tulpn`）；  
  4. 抓包分析：用 `tcpdump` 捕获网络包，通过 Wireshark 分析是否有丢包、重置（RST）等情况；  
  5. 检查中间件：如防火墙、网关是否有拦截规则，负载均衡器是否健康。  

- **解决措施**：  
  1. 增加超时重试机制（如设置合理的连接超时、读取超时）；  
  2. 优化网络配置（如调整 TCP 超时参数、增大 socket 缓冲区）；  
  3. 避免长连接闲置过久（定期发送心跳包）；  
  4. 服务端扩容或限流，避免因过载导致连接被终止。  


### 34. http整个流程，说细致一点？
1. **建立连接**：客户端通过 TCP 三次握手与服务器建立连接；  
2. **发送请求**：客户端构造 HTTP 请求（包含请求行、请求头、请求体）：  
   - 请求行：`Method URL HTTP/Version`（如 `GET /index.html HTTP/1.1`）；  
   - 请求头：如 `Host`、`User-Agent`、`Cookie` 等；  
   - 请求体：POST 等方法携带的数据（如表单参数）。  
3. **服务器处理**：  
   - 解析请求，根据 URL 和方法执行对应业务逻辑；  
   - 处理权限验证、路由匹配、数据查询等操作。  
4. **返回响应**：服务器构造 HTTP 响应（包含状态行、响应头、响应体）：  
   - 状态行：`HTTP/Version StatusCode Reason`（如 `HTTP/1.1 200 OK`）；  
   - 响应头：如 `Content-Type`、`Content-Length`、`Set-Cookie` 等；  
   - 响应体：返回的具体数据（如 HTML、JSON）。  
5. **关闭连接**：  
   - HTTP/1.0 默认关闭连接；  
   - HTTP/1.1 可通过 `Connection: keep-alive` 保持连接，用于后续请求复用。  


### 35. tcp什么情况会出现timewait？
TCP 连接关闭时，主动关闭连接的一方在发送最后一个 ACK 后，会进入 TIME_WAIT 状态（默认持续 2MSL，约 1-4 分钟）。  
常见场景：  
- 客户端主动断开与服务器的连接（如浏览器关闭页面）；  
- 服务器作为主动关闭方（如处理完请求后主动断开）；  
- 异常断开后，主动关闭方未收到最终确认，触发 TIME_WAIT。  

作用：确保最后一个 ACK 被对方收到，避免旧连接的延迟数据包干扰新连接。


### 36. Linux 常见指令，awk使用过么？
- **常见指令**：  
  - 文件操作：`ls`、`cp`、`mv`、`rm`、`cat`、`grep`、`find`；  
  - 进程管理：`ps`、`top`、`kill`、`pstree`；  
  - 网络管理：`ifconfig`、`netstat`、`ping`、`curl`；  
  - 权限管理：`chmod`、`chown`。  

- **awk 使用**：  
  用于文本处理，按行解析并处理字段。例如：  
  - 提取文件第 2 列：`awk '{print $2}' file.txt`；  
  - 按条件过滤（第 3 列大于 100）：`awk '$3 > 100 {print $0}' data.txt`；  
  - 统计某列总和：`awk '{sum += $1} END {print sum}' nums.txt`。  


### 37. 设计一个订单模块，在并发量大的情况下，如何做到服务稳定性和订单不超卖？
- **服务稳定性**：  
  1. 接口限流：用令牌桶/漏桶算法限制请求速率，避免过载；  
  2. 服务集群：部署多实例，通过负载均衡分散流量；  
  3. 异步处理：非核心流程（如通知、日志）通过 MQ 异步化，减少响应时间；  
  4. 缓存热点数据：将商品库存、用户信息等缓存在 Redis，减少 DB 压力；  
  5. 熔断降级：用 Sentinel/Hystrix 监控接口，异常时降级非核心功能。  

- **防止超卖**：  
  1. 库存预扣减：下单时先扣减 Redis 缓存库存（加分布式锁保证原子性），再异步同步到 DB；  
  2. DB 层校验：最终库存以 DB 为准，更新时用 `WHERE stock > 0` 条件（`UPDATE product SET stock = stock - 1 WHERE id = ? AND stock > 0`）；  
  3. 分布式锁：用 Redis/ZooKeeper 实现锁，确保同一商品并发下单时只有一个请求能操作库存；  
  4. 消息队列：订单请求入队，按顺序处理，避免并发冲突。  


### 38. 若是第三方组件（mq，redis缓存，分布式锁）失效了？怎么办？降级操作，如何保证订单不超卖？
- **第三方组件失效处理**：  
  1. **快速失败**：通过熔断机制（如设置超时时间），避免请求阻塞；  
  2. **降级策略**：  
     - MQ 失效：暂时走本地队列或直接落库，后续补处理；  
     - Redis 失效：直接查询 DB，限制单用户请求频率；  
     - 分布式锁失效：改用 DB 行锁（`SELECT ... FOR UPDATE`）。  

- **降级时保证不超卖**：  
  1. 依赖 DB 层强校验：所有库存扣减必须带 `stock > 0` 条件，确保最终一致性；  
  2. 单库单表：若分库分表，降级为单库单表操作，用表锁/行锁控制并发；  
  3. 库存预占：下单时生成唯一订单号，预占库存并设置过期时间，超时未支付自动释放；  
  4. 事后校验：定时任务比对订单与库存，发现超卖后触发补偿（如取消订单、通知用户）。
 

### 39. redolog和undolog
- **redo log（重做日志）**：  
  用于保证事务持久性，记录数据页的物理修改（如“将id=1的行age字段从20改为30”）。事务执行时实时写入，即使数据库崩溃，重启后可通过redo log恢复未提交但已写入的修改。  
- **undo log（回滚日志）**：  
  用于事务回滚和MVCC（多版本并发控制），记录数据修改前的逻辑状态（如“id=1的行age字段原本是20”）。事务回滚时通过undo log恢复数据，查询时通过undo log读取历史版本。  


### 40. 如何实现排行榜
- **基于Redis ZSet**：  
  将用户ID作为member，分数（如积分、次数）作为score，利用ZSet的有序性实现排行榜：  
  - 新增/更新排名：`ZADD rankboard score user_id`；  
  - 获取前N名：`ZRANGE rankboard 0 N-1 WITHSCORES`（升序）或`ZREVRANGE`（降序）；  
  - 获取用户排名：`ZRANK rankboard user_id`（升序排名）或`ZREVRANK`（降序排名）。  
- **优化**：按时间分片（如日榜、周榜），定期更新缓存，高并发时加锁避免分数计算冲突。  


### 41. 如何避免超卖
- **库存预扣减**：下单时先扣减缓存库存（Redis），并加分布式锁保证原子性；  
- **数据库校验**：最终扣减以数据库为准，用`UPDATE ... WHERE stock > 0`（如`UPDATE goods SET stock = stock - 1 WHERE id = ? AND stock > 0`）；  
- **队列串行化**：订单请求入MQ，按商品ID分区串行处理，避免并发冲突；  
- **库存预热与限购**：活动前将库存同步到缓存，限制单用户购买数量，防止恶意抢购。  


### 42. golang切片和数组区别
- **数组**：长度固定（声明时指定，如`[5]int`），值类型，赋值或传参时复制整个数组，内存占用固定。  
- **切片**：长度可变（`[]int`），引用类型，底层指向数组，包含指针、len、cap，赋值或传参时复制结构体（不复制底层数组），可动态扩容。  
- 核心差异：数组长度编译期确定，切片长度运行时可变；数组传递成本高，切片更适合作为动态集合使用。  


### 43. mysql锁
- **按粒度**：  
  - 行锁：锁定单行数据（如InnoDB的`SELECT ... FOR UPDATE`），并发度高；  
  - 表锁：锁定整张表（如MyISAM的`LOCK TABLES`），并发度低；  
  - 页锁：锁定数据页（InnoDB支持，粒度介于行锁和表锁之间）。  
- **按功能**：  
  - 共享锁（S锁）：允许多个事务读，不允许写；  
  - 排他锁（X锁）：禁止其他事务读写；  
  - 意向锁：表级锁，标识事务将要加行锁的类型（如意向共享锁IS、意向排他锁IX）。  
- **特殊锁**：  
  - 间隙锁：锁定索引区间，防止插入幻影行；  
  - 自增锁：插入自增列时的特殊表锁。  


### 44. mysql索引
- **类型**：  
  - 主键索引：唯一且非空，InnoDB中为主键聚簇索引（数据与索引存储在一起）；  
  - 二级索引：基于非主键字段，叶子节点存储主键值；  
  - 联合索引：多字段组合，遵循最左前缀原则；  
  - 全文索引：用于文本模糊查询。  
- **底层结构**：InnoDB用B+树（叶子节点有序且相连，适合范围查询），哈希索引适用于等值查询（Memory引擎支持）。  
- **作用**：加速查询（减少扫描行数），约束数据（如唯一索引保证唯一性）。  


### 45. Redis数据类型
- **String**：二进制安全字符串，可存文本、数字，支持`SET`/`GET`/`INCR`等操作；  
- **Hash**：键值对集合，适合存储对象，支持`HSET`/`HGET`/`HGETALL`；  
- **List**：有序字符串列表，支持两端插入/删除（`LPUSH`/`RPOP`）；  
- **Set**：无序去重集合，支持交集、并集（`SINTER`/`SUNION`）；  
- **ZSet**：带分数的有序集合，按分数排序（`ZADD`/`ZRANGE`）；  
- 其他：Bitmap（位操作）、HyperLogLog（基数统计）、Geospatial（地理位置）。  


### 46. Redis分布式锁
- **实现原理**：用`SET key value NX PX timeout`命令，`NX`确保唯一获取锁，`PX`设置过期时间防死锁。  
- **核心步骤**：  
  1. 获取锁：`SET lock:goods:1 uuid NX PX 30000`（30秒过期）；  
  2. 释放锁：用Lua脚本`if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) end`，确保原子性；  
  3. 续约：通过看门狗协程定期延长锁有效期（如每10秒续期30秒）。  


### 47. redolog必要性
- 保证事务持久性：即使事务未提交时数据库崩溃，重启后可通过redo log恢复已执行的修改；  
- 减少磁盘IO：redo log按顺序写入（追加操作），比直接写入数据文件（随机IO）更高效；  
- 支持事务并发：多个事务的redo log可并行写入，不阻塞事务执行，提升性能。  
- 是InnoDB实现ACID中“持久性（Durability）”的核心机制。

### 48. 限流场景下，令牌桶是怎么实现的，有哪些考虑（结合实际业务讨论有哪些调整）
- **令牌桶实现原理**：  
  系统以固定速率（如100个/秒）向桶中放入令牌，请求到来时需从桶中获取令牌，获取成功则处理请求，令牌不足则限流（排队/拒绝）。桶有最大容量，令牌满后不再新增。  

- **核心考虑与业务调整**：  
  1. **令牌生成速率**：根据业务峰值QPS设置（如秒杀场景临时提高速率）；  
  2. **桶容量**：应对突发流量（如容量设为峰值QPS的1.5倍，避免瞬间流量冲击）；  
  3. **限流策略**：核心接口（如支付）采用排队等待，非核心接口（如评论）直接拒绝；  
  4. **动态调整**：结合监控系统，在流量低谷降低速率节省资源，高峰前预热令牌桶；  
  5. **分布式场景**：用Redis实现分布式令牌桶（如基于计数器+过期时间模拟令牌生成），避免单节点瓶颈。  


### 49. Redis的缓存淘汰策略
Redis在内存达到`maxmemory`时，通过以下策略淘汰键：  
- **volatile-lru**：淘汰设置了过期时间的最近最少使用键；  
- **allkeys-lru**：淘汰所有键中最近最少使用的；  
- **volatile-lfu**：淘汰设置了过期时间的最不经常使用键（4.0+）；  
- **allkeys-lfu**：淘汰所有键中最不经常使用的（4.0+）；  
- **volatile-random**：随机淘汰设置了过期时间的键；  
- **allkeys-random**：随机淘汰所有键；  
- **volatile-ttl**：淘汰设置了过期时间且剩余时间最短的键；  
- **noeviction**：默认策略，不淘汰键，新写入会返回错误。  

选择依据：读多写少用LRU/LFU，键过期时间明确用volatile-ttl，均匀访问用random。  


### 50. Redis热点数据处理的实现和应用
- **实现方式**：  
  1. **本地缓存**：热点数据（如首页商品）在应用本地缓存一份（如用`sync.Map`），减少Redis访问；  
  2. **集群分片**：将热点key分散到不同Redis节点（如按key哈希分片），避免单节点过载；  
  3. **读写分离**：热点读数据由从节点承担，主节点负责写；  
  4. **key拆分**：将大热点key拆分为多个子key（如`hot:1`、`hot:2`），分散访问压力。  

- **应用场景**：  
  - 电商秒杀商品信息、首页推荐列表；  
  - 直播平台在线人数、热门礼物榜单；  
  - 新闻APP头条内容、热点话题。  


### 51. 缓存数据一致性问题，如何保证一致性，那强一致性呢（分析延迟双删和加锁各自的优缺点）
- **缓存一致性目标**：保证缓存与数据库数据最终一致（强一致性极难实现）。  

- **延迟双删**：  
  - 流程：更新DB → 删除缓存 → 延迟（如500ms）→ 再次删除缓存。  
  - 优点：无锁，性能高，适合读多写少场景；  
  - 缺点：延迟时间难确定（过短可能删不干净，过长影响性能），无法保证强一致性。  

- **加锁**：  
  - 流程：更新时加分布式锁 → 先更新DB → 再删缓存 → 释放锁；读操作也需加锁，避免脏读。  
  - 优点：能保证较高一致性，适合写操作频繁场景；  
  - 缺点：锁竞争影响性能，可能导致死锁，仍无法完全实现强一致性（分布式环境下网络延迟可能引发不一致）。  

- **强一致性**：几乎无法实现，需牺牲性能（如缓存与DB同事务，或禁用缓存直接读DB），仅适合严格要求一致性的场景（如金融核心交易）。  


### 52. 分布式系统接口如何保证幂等（"一锁二判三更新"）
- **"一锁二判三更新"流程**：  
  1. **加锁**：获取分布式锁（如Redis锁），确保同一请求串行处理；  
  2. **判断**：查询资源当前状态（如订单是否已创建），若已处理则直接返回结果；  
  3. **更新**：执行业务逻辑（如创建订单），确保操作原子性（如DB事务）。  

- **其他补充手段**：  
  - 用唯一ID（如订单号、请求ID）标识请求，通过Redis/DB记录已处理ID；  
  - 基于状态机设计（如订单状态从“待创建”→“已创建”，避免重复更新）；  
  - 写操作返回唯一结果（如插入成功返回ID，重复插入返回已有ID）。  


### 53. Mysql分表，按照什么维度划分，如何考虑分片键，各有什么问题
- **分表维度与分片键选择**：  
  1. **按时间维度**（如订单表按月份分表）：  
     - 分片键：`create_time`；  
     - 优点：冷热数据分离，历史数据可归档；  
     - 问题：热点集中（如当前月份表访问频繁），跨时间查询复杂。  

  2. **按用户ID哈希**（如用户相关表）：  
     - 分片键：`user_id`；  
     - 优点：数据分布均匀，适合用户维度查询；  
     - 问题：跨用户查询需聚合多表，扩容时需迁移数据。  

  3. **按地区/业务线**（如全国业务按省份分表）：  
     - 分片键：`region_id`；  
     - 优点：符合业务逻辑，便于权限控制；  
     - 问题：地区数据量不均（如一线城市表过大）。  

- **核心原则**：分片键需高频出现在查询条件中，避免全表扫描；平衡数据分布，减少跨分片操作。  


### 54. 慢SQL优化
- **优化步骤**：  
  1. 用`explain`分析执行计划，定位问题（如全表扫描、索引失效）；  
  2. **索引优化**：为查询字段添加合适索引（避免冗余索引），联合索引遵循最左前缀原则；  
  3. **SQL改写**：  
     - 避免`select *`，只查必要字段；  
     - 拆分复杂子查询为join；  
     - 用`limit`限制返回行数，避免大结果集；  
  4. **表结构优化**：  
     - 分表分库（水平/垂直拆分）；  
     - 增加中间表存储计算结果，减少联表查询；  
  5. **参数调优**：调整MySQL配置（如`innodb_buffer_pool_size`、`join_buffer_size`）。  


### 55. 索引失效的原因以及解决办法
- **失效原因及解决**：  
  1. **索引列用函数/表达式**（如`SUBSTR(name,1,3) = 'abc'`）→ 改为在应用层处理函数逻辑，直接用列名查询；  
  2. **联合索引不满足最左前缀**（如`(a,b,c)`仅用`b`查询）→ 调整查询条件包含前缀列，或新增适合的索引；  
  3. **字符串与数字比较**（如`id = '123'`，`id`为int）→ 统一类型，用数字查询；  
  4. **`LIKE '%xxx'`** → 改用全文索引，或业务允许时用`LIKE 'xxx%'`（匹配前缀）；  
  5. **`OR`连接无索引字段** → 改为`UNION`，或为所有字段加索引；  
  6. **索引列有大量重复值** → 放弃索引，直接全表扫描（选择性低时索引效率差）。
 
### 56. Java和Golang的各自优缺点
#### Java的优点
1. **生态成熟丰富**：拥有海量开源库（如Spring、MyBatis）和框架，覆盖Web开发、大数据、人工智能等几乎所有领域，开发效率高。
2. **跨平台能力强**：基于JVM实现“一次编译，到处运行”，无需针对不同操作系统单独编译，适配性广。
3. **面向对象完善**：封装、继承、多态特性完整，支持接口、泛型等，适合构建复杂、大型的模块化项目。
4. **内存管理稳定**：JVM的垃圾回收机制成熟，支持分代回收、G1等多种GC算法，内存泄漏风险较低，对开发者内存管理要求低。
5. **企业级应用适配好**：长期占据企业后端开发主流，支持分布式事务、微服务治理（如Dubbo、Spring Cloud），适合高并发、高可用的大型系统。

#### Java的缺点
1. **启动与运行内存开销大**：JVM初始化需要加载类库，进程内存占用较高（通常数百MB起步），不适合轻量级场景（如边缘计算、小型工具）。
2. **语法较繁琐**：需编写大量模板代码（如POJO类的getter/setter），虽然Lombok可简化，但仍比简洁型语言复杂。
3. **并发编程门槛高**：基于线程和锁的并发模型，需手动处理线程池、锁竞争等问题，容易出现死锁、线程安全隐患，代码调试难度大。
4. **编译速度相对慢**：尤其是大型项目，类文件多、依赖复杂，编译耗时较长，影响开发迭代效率。

#### Golang的优点
1. **轻量高效**：编译为机器码，启动速度快（毫秒级），内存占用低（通常数十MB），适合轻量级服务、CLI工具、云原生场景。
2. **并发模型简洁强大**：基于Goroutine（轻量级协程，百万级并发无压力）和Channel，配合GMP调度模型，并发编程无需手动管理线程，代码简洁且安全。
3. **语法简洁易上手**：无复杂语法糖，关键字少，支持自动垃圾回收，同时保留指针（但限制指针运算），兼顾开发效率与底层控制能力。
4. **编译速度快**：静态编译且依赖管理高效，大型项目编译也能快速完成，适合高频迭代的开发场景。
5. **原生支持网络与并发**：标准库内置完善的HTTP、RPC、并发控制组件（如sync包、Context），无需依赖第三方库即可开发高性能网络服务。

#### Golang的缺点
1. **生态相对较新**：虽然快速发展，但在某些细分领域（如大数据、机器学习）的开源库丰富度不如Java，部分场景需自行开发或适配。
2. **面向对象特性简化**：无类和继承，通过结构体和接口实现类似功能，虽然灵活，但对于习惯传统OOP的开发者需适应，大型项目模块化设计难度略高。
3. **泛型支持较晚且有限**：Go 1.18才引入泛型，且功能不如Java、C#完善（如不支持泛型方法重载），复杂数据结构的复用性受影响。
4. **错误处理较繁琐**：通过返回值（error类型）处理错误，需手动判断每个可能出错的操作，代码中容易出现大量`if err != nil`，影响代码简洁度。
